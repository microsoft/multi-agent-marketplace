OPENAI_API_KEY="todo"
ANTHROPIC_API_KEY="todo"
GEMINI_API_KEY="todo"

LLM_PROVIDER="openai"
LLM_MODEL="gpt-5-nano"
LLM_REASONING_EFFORT="minimal"
# LLM_TEMPERATURE="0" # Set LLM temperature
# LLM_MAX_TOKENS="4000" # Limit 4000 tokens generated
# LLM_MAX_CONCURRENCY="10" # Limit max concurrent requests to the LLM provider